import sys
import time
import asyncio
import threading
import requests
from loguru import logger
from urllib.parse import quote
from datetime import datetime
from zoneinfo import ZoneInfo
from .env_settings import envs

# í˜„ì¬ í™˜ê²½ êµ¬ë¶„
current_env = envs.CURRENT_ENV

# ë¡œê·¸ ì •ì˜
LOG_LEVEL = envs.LOG_LEVEL or "INFO"

# í•œêµ­ ê¸°ì¤€ ì‹œê°„ ì •ì˜
kst_now = datetime.now(ZoneInfo("Asia/Seoul"))


def kst_log_format(record):
    kst_time = record["time"].astimezone(ZoneInfo("Asia/Seoul"))
    formatted_time = kst_time.strftime("%Y-%m-%d %H:%M:%S")
    level = record["level"].name
    # ë¡œê±°ì˜ ë©”ì‹œì§€ê°€ ì¤‘ê´„í˜¸(ex: ê°ì²´ ë“±)ë¡œ ì „ë‹¬ë˜ëŠ” ê²½ìš° í”Œë ˆì´ìŠ¤ í™€ë”ë¡œ í•´ì„í•˜ëŠ” ê²ƒì„ ë°©ì§€
    message = record["message"].replace("{", "{{").replace("}", "}}")

    return f"{formatted_time} | {level} | {message}\n"


def dev_log_format(record):
    kst_time = record["time"].astimezone(ZoneInfo("Asia/Seoul"))
    formatted_time = kst_time.strftime("%Y-%m-%d %H:%M:%S")
    level = record["level"].name
    message = record["message"].replace("{", "{{").replace("}", "}}")

    return f"{formatted_time} | <level>{level}</level> | {message}\n"


# ê¸°ë³¸ í•¸ë“¤ëŸ¬ ì œê±°
logger.remove()

# ë¡œê·¸ ë ˆë²¨ë³„ ìƒ‰ìƒ ì»¤ìŠ¤í„°ë§ˆì´ì§•
logger.level("DEBUG", color="<cyan>")
logger.level("INFO", color="<green>")
logger.level("WARNING", color="<yellow>")
logger.level("ERROR", color="<red><bold>")
logger.level("CRITICAL", color="<magenta><bold>")

# ê¸°ë³¸ í•¸ë“¤ëŸ¬ ì¶”ê°€(ê°œë°œ í™˜ê²½ ê°€ì •)
logger.add(
    sys.stdout,
    level=LOG_LEVEL.upper(),
    format=dev_log_format,
    colorize=True,
    enqueue=False,  # ë™ê¸° ì²˜ë¦¬ë¡œ ë³€ê²½
)


# Redis ì €ì¥ í•¨ìˆ˜
async def save_redis_log(message):
    from .redis_client import redis_log_client

    record = message.record
    log_entry = kst_log_format(record)
    await redis_log_client.rpush("log_entries", log_entry)


# production í™˜ê²½ì¸ ê²½ìš°ì—ë§Œ ë¡œê·¸ë¥¼ B2 ë²„í‚·ì— ì—…ë¡œë“œ
if current_env == "production":
    logger.add(
        save_redis_log,
        level=LOG_LEVEL.upper(),
        colorize=True,
        enqueue=False,  # ë™ê¸° ì²˜ë¦¬ë¡œ ë³€ê²½
    )

    # ë™ê¸° í•¨ìˆ˜ë¡œ êµ¬í˜„í•˜ì—¬ ì´ë²¤íŠ¸ ë£¨í”„ ë¬¸ì œ í•´ê²°
    def flush_logs_to_b2_sync():
        import redis.asyncio as redis
        from app.services import get_upload_url_b2

        # logger ì €ì¥ìš© redis í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        redis_log_client = redis.Redis(
            host=envs.REDIS_HOST,
            port=envs.REDIS_PORT,
            db=envs.REDIS_LOG_DB,
            username=envs.REDIS_USER if current_env == "development" else None,
            password=envs.REDIS_PASSWORD
            if current_env == "development"
            else None,
        )

        # ìƒˆ ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„± ë° ì‹¤í–‰
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        # ìƒíƒœ ë³„ redis í‚¤ ì´ë¦„ ì„¤ì •
        main_key = "log_entries"
        pending_key = "log_entries:pending"

        try:
            # ì›ìì ìœ¼ë¡œ ê¸°ì¡´ ë¡œê·¸ pendingìœ¼ë¡œ ì´ë™
            exists_future = redis_log_client.exists(main_key)
            exists = loop.run_until_complete(exists_future)
            if exists:
                # RENAMEì€ ì›ìì (í‚¤ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬ë‚˜ë¯€ë¡œ ì¡´ì¬í•  ë•Œë§Œ ì§„í–‰)
                rename_future = redis_log_client.rename(main_key, pending_key)
                loop.run_until_complete(rename_future)
            else:
                logger.warning("âš ï¸ ì—…ë¡œë“œ í•  ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return

            # pending í‚¤ì—ì„œ ëª¨ë“  ë¡œê·¸ ì½ê¸°
            get_logs_future = redis_log_client.lrange(pending_key, 0, -1)
            log_entries = loop.run_until_complete(get_logs_future)
            logs = (
                [entry.decode("utf-8") for entry in log_entries]
                if log_entries
                else []
            )

            if not logs:
                logger.warning("âš ï¸ ì—…ë¡œë“œí•  ë¡œê·¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                loop.run_until_complete(redis_log_client.delete(pending_key))
                return

            # ë¡œê·¸ ë‚´ìš© êµ¬ì„±
            content = "".join(logs)
            current_kst = datetime.now(ZoneInfo("Asia/Seoul"))

            # B2 ì—…ë¡œë“œ URL ê°€ì ¸ì˜¤ê¸°
            upload_info = loop.run_until_complete(get_upload_url_b2())
            if not upload_info:
                logger.error("âŒ B2 ì—…ë¡œë“œ URL ì •ë³´ë¥¼ ì–»ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                raise Exception("B2 ì—…ë¡œë“œ URL ì •ë³´ë¥¼ ì–»ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

            upload_url = upload_info.get("uploadUrl")
            token = upload_info.get("authorizationToken")

            # íŒŒì¼ ì´ë¦„ ì„¤ì •
            file_name = quote(
                "logs/PRODUCT_RECOMMEND_{}.log".format(
                    current_kst.strftime("%Y%m%d%H%M%S")
                )
            )
            headers = {
                "Authorization": token,
                "Content-Type": "text/plain; charset=utf-8",
                "X-Bz-File-Name": file_name,
                "X-Bz-Content-Sha1": "do_not_verify",
            }

            # B2ì— ì—…ë¡œë“œ
            response = requests.post(
                upload_url, data=content.encode("utf-8"), headers=headers
            )

            response.raise_for_status()
            logger.info("âœ… ë¡œê·¸ê°€ ì„±ê³µì ìœ¼ë¡œ B2ì— ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

            # ì—…ë¡œë“œ ì„±ê³µ ì‹œ pending ë¡œê·¸ ì‚­ì œ
            loop.run_until_complete(redis_log_client.delete(pending_key))
            logger.info("ğŸ—‘ï¸ ì„ì‹œ ì €ì¥ëœ ë¡œê·¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            logger.error("âŒ ë¡œê·¸ í”ŒëŸ¬ì‹œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: " + str(e))
            # ì—…ë¡œë“œ ì‹¤íŒ¨ ì‹œ, pending ë¡œê·¸ë“¤ì„ ë©”ì¸ í‚¤ë¡œ ë³µêµ¬í•˜ëŠ” ì›ìì  Lua ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
            try:
                lua_script = """
                            local pending = KEYS[1]
                            local main = KEYS[2]
                            local logs = redis.call('LRANGE', pending, 0, -1)
                            if #logs > 0 then
                                for i=1, #logs do
                                    redis.call('RPUSH', main, logs[i])
                                end
                            end
                            return redis.call('DEL', pending)
                            """
                restore_script = redis_log_client.register_script(lua_script)
                loop.run_until_complete(
                    restore_script(keys=[pending_key, main_key])
                )

                logger.info("â—ï¸ì—…ë¡œë“œ ì‹¤íŒ¨ë¡œ ì¸í•œ ë¡œê·¸ ë³µêµ¬ ì™„ë£Œ")
            except Exception as restore_err:
                logger.error("âŒ ë¡œê·¸ ë³µêµ¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: " + str(restore_err))
        finally:
            # Redis ì—°ê²° ì¢…ë£Œ ë° ì´ë²¤íŠ¸ ë£¨í”„ ë‹«ê¸°
            close_future = redis_log_client.close()
            loop.run_until_complete(close_future)
            loop.close()

    def automate_log_flush(interval):
        while True:
            time.sleep(interval)
            try:
                flush_logs_to_b2_sync()
            except Exception as e:
                logger.error("âŒ ë¡œê·¸ í”ŒëŸ¬ì‹œ ìë™í™” ì¤‘ ì˜ˆì™¸ ë°œìƒ: " + str(e))

    # ìë™ ë¡œê·¸ í”ŒëŸ¬ì‹œ (1ì‹œê°„ ë§ˆë‹¤ í•œ ë²ˆì”© ì—…ë¡œë“œ)
    flush_thread = threading.Thread(
        target=automate_log_flush, args=(60 * 60,), daemon=True
    )
    flush_thread.start()

    # ì„¸íŒ… í™•ì¸ì„ ìœ„í•œ í…ŒìŠ¤íŠ¸ ë¡œê·¸ (ì›í•˜ëŠ” ê²½ìš° ì£¼ì„ í•´ì œ)
    # logger.debug("This is a DEBUG message")
    # logger.info("This is an INFO message")
    # logger.warning("This is a WARNING message")
    # logger.error("This is an ERROR message")
    # logger.critical("This is a CRITICAL message")
